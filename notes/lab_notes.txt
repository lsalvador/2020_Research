#Jan 21st
today, we look to start an analysis to see which assembly configuration results in the best
genome assembly data for M. bovis reads.

I want to take 100 random genomes from the dataset, assemble them in 4 different ways and then compare their
cumulative z-scores. This will be a supplement to the research I ultimately work on.

The scripts I designed will be used to assemble the reads using SPAdes and multi-proccessing.

set up a github for my 2020 research.

via Liliana, here are some things to do:
1. Check how many genomes are missing from our repository - compare with the list of 860 isolates
-> I had 667 isolates in total, liliana had 860. after writing a script, I discovered 658 of the isolates
I had were shared between me and liliana
2. Identify from this list, the isolates chosen for your study
-> I did this and we can find the isolates in the data_i_need.txt file
3. Create script to do the download automatically in R
-> Will try to code this tonight
4. Download M. bovis genomes from NCBI
->
5. Pangenome pipeline…
-> first step is to figure out how to get the best quality. generate data with QUAST,
then plot the associated violin plots.
6. Explore mpi4python on GACRC
-> Can do the same thing with multiprocessing in python. mpi4py is not available for

#Jan 22nd
Still working on the tasks Liliana sees as important, which were stated above.

Will try and figure out how to use mpi4py to write parallel applications. trouble is that it is not on
sapelo2 cluster, so I would have to ask to download it.

in my full data folder, I have 667 pair read genomes. Match the year+ID with the new IDs that Liliana
was working with. The sequences I need are in the data_i_need.txt file.

#Jan 23rd
Today, will focus on the timeline for liliana, and coding the script for M. bovis downloads.

#Jan 27th
today, there are 3 tasks that need to be done before I can relax.
1. learn mpi4py
-> I can test my scripts on the cluster at least, but right now I am getting errors that I can't easily
answer. hopefully the GACRC will get back to me soon about how to avoid
2. web scrape SRA selector tool using R selenium.
-> So Liliana wants a tool that can check the database and see if there is anything new? and if not,
just report nothing is new. Otherwise, update the table. I will spend time on this tonight.
3. Start the outline for Pangenome Review
-> Push to tonight or tomorrow. If tomorrow I'll make this the first thing I do.
4. Try to change the names I don't have to the sequence names.
-> Will have to wait for liliana to give me the proper names.

#Jan 29th
The big task for today is to map the original sequence file names to the naming convention that Liliana
has. but we have to wait for the cluster to come up again for that to happen.

In the meantime, I still can read and write for the pangenome review. also, there is additional
work that should be done to generalize my web scraping tool, SRA_scraper.r

#Jan 30th
Notes for the paper: A Pan-Genomic Approach to Understand the Basis of Host Adaptation in Achromobacter
(Jeukens, J., et al., 2017)
Background:
Bacteria in the Achromobacter genus are considered emerging opportunistic pathogens. This means
that the bacteria can be infectious in the presence of a unique opportunity such as immuno-compromised individual.
Specifically, these bacteria are opportunistic in the sense that it looks for hosts that suffer from
Cystic Fibrosis Lung Infection.

The Genomes of this genus range from 6-7 Mb, and are found naturally in the environment. One thing
that makes this bacteria interesting but scary at the same time is that it can easily acquire antibiotic
resistance (The paper that mentions this phenomena reports that this happens through HGT).

The knowledge gap presented in this paper deals with the fact that there has not yet been a proper
comparative genomic studies of the species within the Achromobacter genus, and the taxonomy of these
species was not resolved either. In order to address these questions, pangenomics was utilized to 1)
figure out the histories of genus species and 2) Identify the genes that associate with virulence,
antimicrobial resistance, and host adaptation.

Methods:
4 personally sequences Achromobacter were provided by the researchers. They were fragmented,
amplified using PCR and sequenced using Illumina TruSeq to give 300 length pair reads. The dataset was
assembled using a de-novo approach, which means that the reads were compared to one-another to
see how well they overlap. The hope is to find contiguous sequences from the overlap of the reads
and treat this as the genome to do analysis on. The rest of the data came from online repositories.

The point of generating the assemblies is to prepare them for pangenomic analysis. The pan genome consists
of the core and accessory genome. The core genome contains genes that are conserved by virtually all of
the samples that are being compared, while the accessory genome has genes that are variable in presence.
At the time of this research in 2017, contemporary popular tools such as Roary and even the newer tool
PIRATE have not been published. To define the core and accessory genome, the researchers used a tool
called SaturnV (Which I suspect was just because the author of the paper worked in the same school as
the author of the pangenome inference software).

Once the Core genome was inferred, the standard way to analyze the data is to first find the best substitution
model (Here, they used JModelTest v2) and then use the model to infer a maximum likelihood tree with bootstrap
support. RAxML with 1000 bootstraps were used (Is this overkill? wouldn't 100 bootstraps more or less
say the same thing?) The resulting tree is then midpoint rooted.

Average Nucleotide Identity (or ANI) was computed between all the genome pairs in this analysis.
ANI is a metric to compute how likely two samples are apart of the same species. Typically,
the ANI values between genomes of the same species are above 95% (e.g., Escherichia coli).
Values below 75% are not to be trusted.

Next, it was important to the study to address the goal of seeing which genomic elements associated
with pathogenecity. Genes that were under positive selection were inferred (dN/dS > 1) using the HyPhy
implementation of aBSREL (adaptive Branch-Site Random Effects Likelihood). This method s an improved
version of the commonly-used "branch-site" models, which are used to test if positive selection
has occurred on a proportion of branches. As such, aBSREL models both site-level
and branch-level ω heterogeneity.

The other part of the pan-genome involves the accessory genome, which includes the genes that are
variable in presence amongst all the samples. Presence or Absence of inferred genes was held in
a binary matrix. Genes that were were unique to a given genome were expunged. The similarity in
accessory genome composition was assessed using PCA. A technique called discriminant analysis of
principle components known as DAPC was used to determine the genes that distinguish between two classes
of isolates (Clinical and Non Clinical)

Another important thing to consider when analyzing the pangenome is to know if the pan genome is
opened or closed. An open pangenome means that the number of genes will increase as long
as new genomes are added to the analysis. a closed pangenome means that the pangenome of a species
is set once a certain threshold of genomes has been added. To establish the nature of the Achromobacter
pangenome, the no. of genes were calculated after successive addition of random genomes until 29 genomes
were compared. this procedure was repeated 10 times to generate two plots, 1) how many total Genes
are added with additional genomes and 2) how many new genes are added with additional genomes.

This won't be extremely applicable to my research, but I'll briefly gloss over the identification
of the Mobilome and the Resistome. The Mobilome is basically the genetic elements in the genome that are
due to horizontal gene transfer. this can be studied by doing meta-genomics on the isolates and seeing Which
regions correspond to foreign inserts. In this paper, they used NCBI BLAST (MegaBLAST) against the
NCBI nucleotide database to see which elements were there due to HGT. The Resistome is basically genes
that are important for antimicrobial resistance. Simply put they used BLASTp against the
Comprehensive Antibiotic Resistance Database (CARD).

#Feb 2nd
Just for my cross referencing.

So Liliana wants to know what types of data we have in sapelo2. I figured that out by matching
the read ID with the naming convention that we have. Liliana had a naming convention of 860,
and we had 667 isolates. Doing my method, we were able to get 658 that had similarity from the list
Liliana had.

Now, I'm trying to see which data I subsampled is represented in the available data.
I sampled 359 samples. This is a bit harder for some reason, and I am only able
to recover a portion of this 359, but not the whole thing. With the frustration, I'd rather just
do something simpler

#Feb 4th
worked with nCov working group to create a network for the airport travel. Successfully made a
incidence grap but will work further to try and make informative visualizations

Spoke with Liliana yesterday and we think to test the methods we should use the Elk paper
dataset. will compile them now. Will be running over night.

#Feb 5th
Today will be the day we assembly the Michigan data. I have 126 isolates collected from lab_shared.
will trim reads first, using sickle. (Would like to finish this today at least)

We also have a reading and writing session today at 1:30 - 3:30 today. After that I will be meeting
with Tierney to go over what is in the data.

From 12:10 - 1:20 I will need to print out papers that deal with how to analyze flight data
in the context of pathogen transmission.

#Feb 6th
Spending the day creating the trimmed files dataset. separating them from the untrimmed data /trimmed
and in /raw respectively. will compare the violin plots of the two approaches.

#Feb 9th
Notes for the paper: Coinfinder: Detecting Significant Associations and Dissociations in Pangenomes

Background:
Pangenomes consist of a core genome (genes common across all strains) and a accessory genome (genes variable
in presence.) Since genes that are present in the accessory genome are by definition not important for the
organism (bacteria specifically for this presentation) then their ultimate function is not well known and
open to debate. On a personal note, these genes have been used to account for features of the samples They
represent, detecting features of antibiotic resistance, mobile elements, and pathogenecity (Jeukens, J., et al., 2017)
so there is research that shows how the accessory genome is present.

The paper states that there are expected to be genes that co-occur/co-dissociate with each other
moreso than would be expected. These genes could work together to improve fitness within a host
or when they are present together, they could potentially impact fitness in a negative way. In
order to fully understand the accessory genome, untangling the gene-to-gene interactions that are
statistically significant given our dataset.

Previous methods were developed to untangle this mystery of co-occurence in some respects. tools
such as SparCC is used to find how correlated microbiotic species are in an environment (agnostic of pangenome)
NetShift also studies correlations of microbiotic species, but tries to make distinctions between disease
states and healthy states. Scoary is developed to associate gene products in the accessory genome with
associated metadata.

Gene-Gene correlations are also developed such as CoPAP and Pantagruel, but these methods are
based on phylogenetic methods, and are not able to find gene-gene dissociations. This is what
Coinfinder looks to address the creation of a method that can fully tease apart gene-gene interactions
within a computed accessory genome.

Implementation:
Coinfinder takes in as input a gene_presence_absence.csv that is outputted by popular pangenomic
inference softwares such as Roary and PIRATE. additionally, a core genome tree (or ribosomal RNA)
should be included aswell.

The data is pruned to remove core genes and low abundance genes (from a user defined cutoff).
Coinfinder has an association mode and a dissociation mode. for the association mode, Coinfinder
establishes if gene i and gene j are observed together more than what is statistically expected.

Probability for gene i = Pi = Ni/N  (genomes with gene i)/(all genomes)

We compute the theoretical expected number of associations in to be:
E(ij) = Pi*Pj*N -> how many times should these genes interact given their presence.

The observed amount is defined easily, just count when they are seen together,
O(ij) = Nij -> the number of genomes that gene i and j are in together.

We have everything we need to compute a correlative statistic and determine significance.
For this we use a Bonferroni-corrected (reduce the False Positive Rate) binomial exact test
(how significant is what we observe given what we expect.) The phylogenetic tree can infer if
this is lineage dependent or lineage independent (the more exciting result).

Output of Coinfinder is a network where nodes are genes, and edges are significant interactions.

Results:
To test how this tool can be utilized in a pangenomic pipeline, the researchers extracted data from
the Global Pneumococcal Sequencing Project. 534 Streptococcus pneumoniae specifically.
prokka -> Roary -> Coinfinder

found 104,9444 associative gene pairs, 98,461 dissociative gene pairs.

Coinfinder was able to recapitulate findings that were previously known, such as:
In the annotation of S. pneumoniae that we performed here, only 6 genes of the
ntp operon were annotated successfully: ntpA, ntpB, ntpC, ntpD, ntpG, and ntpK.
Coinfinder identified consistent co-occurrence relationships between these 6 genes

Were able to find new connections that were not yet produced in previous analyses.

#Feb 12th
Writing for two hours today, I think I will focus again on working on my IDEAS proposal
The network project is coming along, I shall write below how I created the data in the R script:

The OAG flight data from January is provided by John Drake
The county data is made from myself, I googled where the location coresponds to a US county
The prefecture data comes from Anna, and I filled in two empty slots by hand, Guangzhou and Wainxan.

#Feb 13th
This is a pretty slow day, but I think I will try and create a python script to automatically run prokka
using multiprocessing. shouldn't take too much work, just need to refactor some code to get me there

#Feb 17th
TODO:
* Pangenome run - DONE
* QUAST run - Needs to be done in
* Pangenome review

#Feb 18th
Move analysis to the /scratch directory, and after finishing move into lab_shared.
